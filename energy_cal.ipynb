{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a777892-7174-4205-bb7d-10f06265da46",
   "metadata": {},
   "source": [
    "### Energy calibration by Clint Wiseman. Copied on 2021-05-25-10:33pm. \n",
    "https://github.com/wcpettus/KrSTC/blob/master/data/energy_cal.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe415d1f-5819-4275-9e8f-3cf29801cf3c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from scipy.optimize import curve_fit\n",
    "import tinydb as db\n",
    "from tinydb.storages import MemoryStorage\n",
    "\n",
    "import matplotlib\n",
    "if os.environ.get('HOSTNAME'): # cenpa-rocks\n",
    "    matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('../clint.mpl')\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas() \n",
    "\n",
    "from pygama import DataGroup\n",
    "from pygama.io.orcadaq import parse_header\n",
    "import pygama.lh5 as lh5\n",
    "import pygama.analysis.metadata as pmd\n",
    "import pygama.analysis.histograms as pgh\n",
    "import pygama.analysis.calibration as pgc\n",
    "import pygama.analysis.peak_fitting as pgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9a1b0b9-8b97-4360-92f8-47c203aa5012",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, DAQ directory not found: $KRSTC_DAQ\n",
      "Loading default calibration parameters from:\n",
      "  /global/cfs/cdirs/legend/software/KrSTC/data/meta/config_ecal.json\n",
      "Ready to calibrate.\n",
      "Output file: ecalDB.json \n",
      "Calibrating raw energy parameters: ['trapEmax'] \n",
      "Current data group (1 files) --->> \n",
      "      run  cycle                     daq_file runtype     startTime  \\\n",
      "341  16.0   2360  2020-6-28-BackgroundRun2360     bkg  1.593385e+09   \n",
      "\n",
      "     threshold      stopTime   runtime  \n",
      "341      100.0  1.593386e+09  14.87028   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    doc=\"\"\"\n",
    "    Energy calibration app for CAGE.\n",
    "\n",
    "    Usage:\n",
    "    First, generate an up-to-date fileDB (setup.py) and DSP files (processing.py).\n",
    "      You will need to run setup.py with --orca and --rt options.\n",
    "    \n",
    "    Select a group of files to calibrate with a query:\n",
    "        $ ./energy_cal.py -q 'run==234 [and cycle <= 345, etc.]'\n",
    "    \n",
    "    Check the raw spectrum with '--raw' (default estimator: trapEmax)\n",
    "    \n",
    "    Adjust the JSON configuration file as needed (default: config_ecal.json)\n",
    "    \n",
    "    Run \"peakdet\", which calculates up to 2nd-order calibration constants for\n",
    "      each channel, y = p0 +  p1 * x  +  p2 * x**2, and saves them as tables\n",
    "      in our ecalDB file.\n",
    "    \n",
    "    Run \"peakfit\", which fits each peak of interest to a peakshape function \n",
    "      (default: gaussian + linear step function), computes calibration \n",
    "      constants, and resolution curves, and saves results to ecalDB.\n",
    "\n",
    "    Results are saved ('-w' option) to JSON format with 'legend-metadata' \n",
    "      style conventions.\n",
    "    \n",
    "    C. Wiseman, T. Mathew, G. Othman, J. Detwiler\n",
    "    \"\"\"\n",
    "    rthf = argparse.RawTextHelpFormatter\n",
    "    par = argparse.ArgumentParser(description=doc, formatter_class=rthf)\n",
    "    arg, st, sf = par.add_argument, 'store_true', 'store_false'\n",
    "\n",
    "    # declare group of files of interest.  supports sql-style(ish) queries\n",
    "    arg('-q', '--query', nargs=1, type=str,\n",
    "        help=\"select file group to calibrate: -q 'run==1 and [condition]' \")\n",
    "    \n",
    "    # primary ops\n",
    "    arg('--raw', action=st, help='display/save uncalibrated energy histogram')\n",
    "    arg('-pd', '--peakdet', action=st, help='first pass: peak detection')\n",
    "    arg('-pi', '--peakinp', nargs=1, type=str, help='first pass: manually input peaks')\n",
    "    arg('-pf', '--peakfit', action=st, help='second pass: individual peak fit')\n",
    "    arg('--all', action=st, help='run all passes, write to DB')\n",
    "\n",
    "    # options\n",
    "    arg('-v', '--verbose', nargs=1, help='set verbosity (default: 1)')\n",
    "    arg('--init_db', action=st, help='initialize ecal database JSON file')\n",
    "    arg('-u', '--lh5_user', action=st, help='user lh5 mode')\n",
    "    arg('-w', '--write_db', action=st, help='write results to ecalDB file')\n",
    "    arg('-s', '--show_db', nargs='*', help='show ecalDB, optionally specify table name')\n",
    "    arg('-p', '--show_plot', action=st, help='show debug plot')\n",
    "    arg('-b', '--batch', action=st, help=\"batch mode: save & don't display plots\")\n",
    "    arg('--show_config', action=st, help='show current configuration')\n",
    "    arg('--match', nargs=1, type=str, help='set peak match mode (default: first)')\n",
    "    arg('--pol', nargs=1, type=int, help='set peakdet/peakinput pol order')\n",
    "    arg('--epar', nargs=1, type=str,\n",
    "        help=\"specify raw energy parameters: --epar 'asd sdf dfg' \")\n",
    "    arg('-gb', '--group', nargs=1, type=str,\n",
    "        help=\"select alternate groupby: -gb 'run cycle' \")\n",
    "    arg('-ff', '--fit_func', nargs=1, type=str, help='set peakfit fit function (default is gaus+step)')\n",
    "    arg('--spec', nargs=1, type=int, help='select alternate set of peaks to calibrate')\n",
    "    args = par.parse_args()\n",
    "\n",
    "\n",
    "    # -- set up fileDB and config dictionary --\n",
    "    \n",
    "    # query the fileDB & modify in-memory to only contain files matching our query\n",
    "    #dg = DataGroup('cage.json', load=True)\n",
    "    dg = DataGroup('krstc.json', load=True)\n",
    "    if args.query:\n",
    "        que = args.query[0]\n",
    "        dg.fileDB.query(que, inplace=True)\n",
    "        show_all = False\n",
    "    else: \n",
    "        dg.fileDB = dg.fileDB[-1:]\n",
    "        show_all = True\n",
    "        \n",
    "    # load ecal config file\n",
    "    #f_ecal = dg.config['ecal_default']\n",
    "    f_ecal = dg.config['ecal_config']\n",
    "    if args.spec:\n",
    "        spec_id = args.spec[0]\n",
    "        if spec_id == 1:\n",
    "            f_ecal = './metadata/config_ecal_ba.json' \n",
    "            print(f'Loading Ba133 calibration parameters from: {f_ecal}')\n",
    "        else:\n",
    "            print('Error, unknown calib mode:', args.spec[0])\n",
    "    else:\n",
    "        print(f'Loading default calibration parameters from:\\n  {f_ecal}')\n",
    "        \n",
    "    # merge main and ecal config dicts\n",
    "    with open(os.path.expandvars(f_ecal)) as f:\n",
    "        config = {**dg.config, **json.load(f)}\n",
    "    \n",
    "    # initialize ecalDB JSON output file.  only run this once\n",
    "    if args.init_db:\n",
    "        init_ecaldb(config)\n",
    "        exit()\n",
    "    try:\n",
    "        # load ecalDB this way (into memory) s/t the pretty on-disk formatting isn't changed\n",
    "        db_ecal = db.TinyDB(storage=MemoryStorage)\n",
    "        with open(config['ecaldb']) as f:\n",
    "            raw_db = json.load(f)\n",
    "            db_ecal.storage.write(raw_db)\n",
    "    except:\n",
    "        print('JSON database file not found or corrupted.  Rerun --init_db')\n",
    "        exit()\n",
    "\n",
    "    # set more options -- everything should be loaded into the 'config' dict\n",
    "    config['gb_cols'] = args.group[0].split(' ') if args.group else ['run']\n",
    "    if config['gb_cols'][0] != 'run':\n",
    "        print(\"Error, first groupby column must be 'run'!  Try -gb 'run cycle'\")\n",
    "        exit() \n",
    "\n",
    "    # set input data directory (CAGE_LH5, CAGE_LH5_USER, or cwd)\n",
    "    lh5_dir = dg.lh5_user_dir if args.lh5_user else dg.lh5_dir\n",
    "    config['lh5_dir'] = os.path.expandvars(lh5_dir)\n",
    "    config['pol'] = args.pol if args.pol else [2]\n",
    "    config['rawe'] = args.epar[0].split(' ') if args.epar else config['rawe_default']\n",
    "    config['match_mode'] = args.match if args.match else 'first'\n",
    "    config['mp_tol'] = 100 # raw peaks must be within keV\n",
    "    config['batch_mode'] = True if args.batch else False\n",
    "    config['show_plot'] = True if args.show_plot else False\n",
    "    config['write_db'] = True if args.write_db else False\n",
    "    if args.peakinp: config['input_id'] = args.peakinp[0]\n",
    "    config['input_peaks'] = './metadata/input_peaks.json'\n",
    "    config['fit_func'] = args.fit_func[0] if args.fit_func else 'gauss_step'\n",
    "    config['verbose'] = args.verbose[0] if args.verbose else 0\n",
    "    \n",
    "    # include fields from ecalDB in the config dict\n",
    "    dg.config = {**config, **db_ecal.table('_file_info').all()[0]}\n",
    "\n",
    "\n",
    "    # -- show status -- \n",
    "    \n",
    "    ecal_cols = ['run', 'cycle', 'daq_file', 'runtype', 'startTime', 'threshold',\n",
    "                 'stopTime', 'runtime']\n",
    "    \n",
    "    if dg.fileDB is None:\n",
    "        print('Warning, no fileDB is loaded.')\n",
    "    \n",
    "    elif not all(x in dg.fileDB.columns for x in ecal_cols):\n",
    "        print('Error, fileDB is missing some columns.  Did you run setup.py?')\n",
    "        print('Current available columns:\\n', dg.fileDB.columns)\n",
    "        exit()\n",
    "    \n",
    "    print(f'Ready to calibrate.\\n'\n",
    "          f\"Output file: {config['ecaldb']} \\n\"\n",
    "          'Calibrating raw energy parameters:', config['rawe'], '\\n'\n",
    "          f'Current data group ({len(dg.fileDB)} files) --->> ')\n",
    "    print(dg.fileDB[ecal_cols], '\\n')\n",
    "    \n",
    "    if args.show_config:\n",
    "        print('Current energy_cal config:')\n",
    "        pprint(config)\n",
    "        print('\\n')\n",
    "        \n",
    "    if args.show_db is not None:\n",
    "        tables = args.show_db # list\n",
    "        show_ecaldb(dg, tables, args.query, show_all)\n",
    "\n",
    "\n",
    "    # -- main routines --\n",
    "    \n",
    "    if args.raw:\n",
    "        check_raw_spectrum(dg, config, db_ecal)\n",
    "    \n",
    "    if args.peakdet: \n",
    "        run_peakdet(dg, config, db_ecal)\n",
    "    \n",
    "    if args.peakfit: \n",
    "        run_peakfit(dg, config, db_ecal)\n",
    "\n",
    "    if args.all:\n",
    "        config['write_db'] = True\n",
    "        run_peakdet(dg, config, db_ecal)\n",
    "        run_peakfit(dg, config, db_ecal)\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f479bea-45ff-415a-82ee-8d39a25c21fd",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, DAQ directory not found: $KRSTC_DAQ\n",
      "Loading default calibration parameters from:\n",
      "  /global/cfs/cdirs/legend/software/KrSTC/data/meta/config_ecal.json\n",
      "Ready to calibrate.\n",
      "Output file: ecalDB.json \n",
      "Calibrating raw energy parameters: ['trapEmax'] \n",
      "Current data group (1 files) --->> \n",
      "      run  cycle                     daq_file runtype     startTime  \\\n",
      "341  16.0   2360  2020-6-28-BackgroundRun2360     bkg  1.593385e+09   \n",
      "\n",
      "     threshold      stopTime   runtime  \n",
      "341      100.0  1.593386e+09  14.87028   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def init_ecaldb(config):\n",
    "    \"\"\"\n",
    "    $ ./energy_cal.py --init_db\n",
    "    one-time set up of primary database file.\n",
    "    You probably DON'T want to run this, it will wipe ecalDB.json\n",
    "    \"\"\"\n",
    "    ans = input('(Re)create main ecal JSON file?  Are you really sure? (y/n) ')\n",
    "    if ans.lower() != 'y':\n",
    "        exit()\n",
    "\n",
    "    f_db = config['ecaldb'] # for pgt, should have one for each detector\n",
    "\n",
    "    if os.path.exists(f_db):\n",
    "        os.remove(f_db)\n",
    "\n",
    "    # create the database in-memory\n",
    "    db_ecal = db.TinyDB(storage=MemoryStorage)\n",
    "    query = db.Query()\n",
    "\n",
    "    # create a table with metadata (provenance) about this calibration file\n",
    "    file_info = {\n",
    "        \"system\" : config['system'],\n",
    "        \"cal_type\" : \"energy\",\n",
    "        \"created_gmt\" : datetime.utcnow().strftime(\"%m/%d/%Y, %H:%M:%S\"),\n",
    "        \"input_table\" : config['input_table']\n",
    "        }\n",
    "    db_ecal.table('_file_info').insert(file_info)\n",
    "\n",
    "    # pretty-print the JSON database to file\n",
    "    raw_db = db_ecal.storage.read()\n",
    "    pmd.write_pretty(raw_db, f_db)\n",
    "\n",
    "    # show the file as-is on disk\n",
    "    with open(f_db) as f:\n",
    "        print(f.read())\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8d66da-9ca0-44bd-885e-bd09aca2ef95",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, DAQ directory not found: $KRSTC_DAQ\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ecal_default'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-17e7ec162342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-3b710e4297a5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# load ecal config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mf_ecal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ecal_default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mspec_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ecal_default'"
     ]
    }
   ],
   "source": [
    "def show_ecaldb(dg, tables=None, query=None, show_all=True):\n",
    "    \"\"\"\n",
    "    $ ./energy_cal.py --show_db [table name]\n",
    "    \n",
    "    if show_all, don't filter by the dg query and use to_string\n",
    "    \"\"\"\n",
    "    print('Loading ecalDB:', dg.config['ecaldb'])\n",
    "    print('  Show all entries?', show_all)\n",
    "    print('  Reading tables:', tables)\n",
    "    \n",
    "    if isinstance(query, list): query = query[0]\n",
    "    print('  Query is:', query)\n",
    "    \n",
    "    # # show the file as-is on disk\n",
    "    # with open(config['ecaldb']) as f:\n",
    "    #     print(f.read())\n",
    "\n",
    "    # make sure the file is usable by TinyDB\n",
    "    db_ecal = db.TinyDB(storage=MemoryStorage)\n",
    "    with open(dg.config['ecaldb']) as f:\n",
    "        raw_db = json.load(f)\n",
    "        db_ecal.storage.write(raw_db)\n",
    "        \n",
    "    # show tables in ecalDB, in pandas format.  user either passes\n",
    "    # a specific table to look at, or we print them all.\n",
    "    if tables is not None and len(tables)==0:\n",
    "        print('No table name given, showing all available tables in ecalDB.')\n",
    "        tables = [tb for tb in db_ecal.tables() if tb != '_file_info']\n",
    "    else:\n",
    "        tb_list = tables\n",
    "    \n",
    "    # show user requested tables\n",
    "    for tb in tables:\n",
    "        print('\\necalDB table:', tb)\n",
    "        db_table = db_ecal.table(tb).all()\n",
    "        df_table = pd.DataFrame(db_table)\n",
    "        \n",
    "        # can't save ints correctly to tinyDB (yet), so fix them here\n",
    "        int_cols = [col for col in ['run','cychi','cyclo','calpass'] if col in df_table.columns]\n",
    "        for col in int_cols:\n",
    "            df_table[col] = df_table[col].astype(int)\n",
    "    \n",
    "        # fix the column order too\n",
    "        cols = ['run','cyclo','cychi']\n",
    "        cols += [c for c in df_table.columns if c not in cols]\n",
    "        \n",
    "        # display table.  if user sends in a query, only show matching entries\n",
    "        if not show_all:\n",
    "            print(df_table.query(query)[cols])\n",
    "        else:\n",
    "            print(df_table[cols].to_string())\n",
    "    \n",
    "\n",
    "def check_raw_spectrum(dg, config, db_ecal):\n",
    "    \"\"\"\n",
    "    $ ./energy_cal.py -q 'query' --raw\n",
    "    \"\"\"\n",
    "    # load energy data\n",
    "    dsp_list = config['lh5_dir'] + dg.fileDB['dsp_path'] + '/' + dg.fileDB['dsp_file']\n",
    "    raw_data = lh5.load_nda(dsp_list, config['rawe'], config['input_table'], verbose=False)\n",
    "    runtime_min = dg.fileDB['runtime'].sum()\n",
    "\n",
    "    print('\\nShowing raw spectra ...')\n",
    "    for etype in config['rawe']:\n",
    "        xlo, xhi, xpb = config['init_vals'][etype][\"raw_range\"]\n",
    "\n",
    "        # load energy data for this estimator\n",
    "        data = raw_data[etype]\n",
    "\n",
    "        # print columns of table\n",
    "        file_info = db_ecal.table('_file_info').all()[0]\n",
    "        tb_in = file_info['input_table']\n",
    "        with h5py.File(dsp_list.iloc[0], 'r') as hf:\n",
    "            print(\"LH5 columns:\", list(hf[f'{tb_in}'].keys()))\n",
    "\n",
    "        # generate histogram\n",
    "        hist, bins, var = pgh.get_hist(data, range=(xlo, xhi), dx=xpb)\n",
    "        bins = bins[1:] # trim zero bin, not needed with ds='steps'\n",
    "\n",
    "        # normalize by runtime\n",
    "        hist_rt = np.divide(hist, runtime_min * 60)\n",
    "\n",
    "        print('\\nPlease determine the following parameters for ecal config file:\\n'\n",
    "              \"  - 'raw_range': Optimal binning, and hi/lo raw energy limits\\n\"\n",
    "              \"  - 'peakdet_thresh': ~1/2 the height of a target peak\\n\"\n",
    "              \"  - 'lowe_cut' energy threshold for peak detection\")\n",
    "\n",
    "        print(f'\\nRaw E: {etype}, {len(data)} cts, runtime: {runtime_min:.2f} min')\n",
    "\n",
    "        plt.semilogy(bins, hist_rt, ds='steps', c='b', lw=1, label=etype)\n",
    "        plt.xlabel(etype, ha='right', x=1)\n",
    "        plt.ylabel(f'cts/sec, {xpb}/bin', ha='right', y=1)\n",
    "\n",
    "        if config['batch_mode']:\n",
    "            plt.savefig('./plots/energy_cal/cal_spec_test.png')\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def run_peakdet(dg, config, db_ecal):\n",
    "    \"\"\"\n",
    "    $ ./energy_cal.py -q 'query' [-pd / -pi inp_id] [-p : show plot] [-w : write ecalDB]\n",
    "    \n",
    "    Run \"first guess\" calibration of a list of energy parameters.\n",
    "    Creates a table in the ecalDB for each one, storing up to 2nd order\n",
    "    polynomials: y = p0  +  p1 * x  +  p2 * x**2.\n",
    "    These are used as inputs to \"peakfit\".\n",
    "\n",
    "    We have two modes:\n",
    "    -- automatic (default): find p1 by matching the ratios of uncalibrated\n",
    "       auto-detected peaks to an input list of peaks in keV.  \n",
    "       Assumes y = p1 * x, which may not always work for all detectors.\n",
    "       \n",
    "    -- \"input peaks\": use a JSON config file to set expected peak locations.\n",
    "       This is useful when the spectrum deviates too much from y = p1 * x.\n",
    "          \n",
    "    Files are grouped by run, and optionally by cycle (calibrates individual files\n",
    "      within the run.)  Right now, we require the first item in gb_cols to be 'run'.\n",
    "      It's also possible to group a subset of files in a run together, with a \n",
    "      query like \"run==123 and cycle > 456\"\n",
    "\n",
    "    We then write several TinyDB 'Tables' to our ecalDB file.  \n",
    "    They have a nice 1--1 correspondence to pandas dataframes.\n",
    "    \"\"\"\n",
    "    gb = dg.fileDB.groupby(config['gb_cols'])\n",
    "    runs = dg.fileDB.run.unique()\n",
    "    cyclo, cychi = dg.fileDB.cycle.iloc[0], dg.fileDB.cycle.iloc[-1]\n",
    "    print(f'Running peakdet, runs {runs}, cycles {cyclo}--{cychi}')\n",
    "    \n",
    "    # run peakdet function as a pandas groupby\n",
    "    if 'input_id' in config.keys():\n",
    "        pol = config['pol'][0]\n",
    "        print(f'Fitting manually input peak locations to polynomial, order', pol)\n",
    "        result = gb.apply(peakdet_input, *[config])\n",
    "    else:\n",
    "        print('Automatically detecting peaks based on input list.')\n",
    "        result = gb.apply(peakdet_auto, *[config])\n",
    "    \n",
    "    def parse_results(df_run):\n",
    "        \"\"\"\n",
    "        for each run, compute entries for each energy estimator to TinyDB\n",
    "        \"\"\"\n",
    "        run = int(df_run.index[0])\n",
    "        \n",
    "        for epar in config['rawe']:\n",
    "            \n",
    "            # format output table\n",
    "            epar_cols = [r for r in df_run.columns if epar in r]\n",
    "            df_epar = df_run[epar_cols].copy()\n",
    "            df_epar.rename(columns={c:c.split('_')[-1] for c in epar_cols},\n",
    "                           inplace=True)\n",
    "            df_epar['calpass'] = df_epar['calpass'].astype(int)\n",
    "            df_epar.reset_index(inplace=True)\n",
    "            \n",
    "            if 'cycle' in df_epar.columns:\n",
    "                # this is redundant with cyclo and cychi\n",
    "                df_epar.drop('cycle', 1, inplace=True)\n",
    "            cyclo, cychi = df_epar.iloc[0][['cyclo','cychi']]\n",
    "            \n",
    "            tb_name = f'peakinp_{epar}' if 'input_id' in config.keys() else f'peakdet_{epar}'\n",
    "            print('Results:', tb_name)\n",
    "            print(f'Run {run}  cycles {cyclo}--{cychi}')\n",
    "            print(df_epar)\n",
    "            \n",
    "            # this is in-memory, no write to file yet\n",
    "            table = db_ecal.table(tb_name)\n",
    "            q = db.Query()\n",
    "            for i, row in df_epar.iterrows():\n",
    "                que = ((q.run==row.run) & (q.cyclo==row.cyclo) & (q.cychi==row.cychi))\n",
    "                table.upsert(row.to_dict(), que)\n",
    "            \n",
    "    # parse the results\n",
    "    result.groupby(['run']).apply(parse_results)\n",
    "        \n",
    "    if not config['write_db']:\n",
    "        print('Done. ecalDB write mode not set (-w option)')\n",
    "        return\n",
    "\n",
    "    # show in-memory state and then write to file\n",
    "    # pprint(db_ecal.storage.read())\n",
    "    print('Writing results to ecalDB.')\n",
    "    pmd.write_pretty(db_ecal.storage.read(), config['ecaldb'])\n",
    "\n",
    "\n",
    "def peakdet_auto(df_group, config):\n",
    "    \"\"\"\n",
    "    Access all files in this group, load energy histograms, and find the\n",
    "    \"first guess\" linear calibration constant.\n",
    "    Return the value, and a bool indicating success.\n",
    "    \"\"\"\n",
    "    # load data and compute runtime\n",
    "    dsp_list = config['lh5_dir'] + df_group['dsp_path'] + '/' + df_group['dsp_file']\n",
    "    edata = lh5.load_nda(dsp_list, config['rawe'], config['input_table'], verbose=False)\n",
    "    runtime_min = df_group['runtime'].sum()\n",
    "    run = df_group.run.iloc[0]\n",
    "    cyclo, cychi = df_group.cycle.iloc[0], df_group.cycle.iloc[-1]\n",
    "    print(f'  Runtime: {runtime_min:.1f} min.  Calibrating:', [f'{et}:{len(ev)} events' for et, ev in edata.items()])\n",
    "\n",
    "    # loop over energy estimators of interest\n",
    "    pd_results = {}\n",
    "    for et in config['rawe']:\n",
    "\n",
    "        # get histogram, error, normalize by runtime, and derivative\n",
    "        xlo, xhi, xpb = config['init_vals'][et]['raw_range']\n",
    "        hist, bins, var = pgh.get_hist(edata[et], range=(xlo, xhi), dx=xpb)\n",
    "        hist_norm = np.divide(hist, runtime_min * 60)\n",
    "        hist_err = np.array([np.sqrt(hbin / (runtime_min * 60)) for hbin in hist])\n",
    "\n",
    "        # run peakdet\n",
    "        pd_thresh = config['init_vals'][et]['peakdet_thresh']\n",
    "        lowe_cut = config['init_vals'][et]['lowe_cut']\n",
    "        ctr_bins = (bins[:-1] + bins[1:]) / 2.\n",
    "        idx = np.where(ctr_bins > lowe_cut)\n",
    "\n",
    "        maxes, mins = pgc.peakdet(hist_norm[idx], pd_thresh, ctr_bins[idx])\n",
    "        # maxes, mins = pgc.peakdet(hist_deriv[idx], pd_thresh, ctr_bins[idx])\n",
    "        if len(maxes)==0:\n",
    "            print('warning, no maxima!  adjust peakdet threshold')\n",
    "        # print(maxes) # x (energy) [:,0], y (counts) [:,1]\n",
    "\n",
    "        # run peak matching\n",
    "        exp_pks = config['expected_peaks']\n",
    "        tst_pks = config['test_peaks']\n",
    "        mode = config['match_mode']\n",
    "        etol = config['raw_ene_tol']\n",
    "        lin_cal, mp_success = match_peaks(maxes, exp_pks, tst_pks, mode, etol)\n",
    "        \n",
    "        if config['show_plot']:\n",
    "\n",
    "            # plot uncalibrated and calibrated energy spectrum, w/ maxima\n",
    "            fig, (p0, p1) = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "            idx = np.where(bins[1:] > lowe_cut)\n",
    "            imaxes = [np.where(np.isclose(ctr_bins, x[0]))[0][0] for x in maxes]\n",
    "            imaxes = np.asarray(imaxes)\n",
    "\n",
    "            # energy, uncalibrated\n",
    "            p0.semilogy(bins[imaxes], hist_norm[imaxes], '.m')\n",
    "            p0.semilogy(bins[idx], hist_norm[idx], ds='steps', c='b', lw=1, label=et)\n",
    "            p0.set_ylabel(f'cts/s, {xpb}/bin', ha='right', y=1)\n",
    "            p0.set_xlabel(et, ha='right', x=1)\n",
    "            p0.set_ylim(1e-4)\n",
    "\n",
    "            # energy, with rough calibration\n",
    "            bins_cal = bins[1:] * lin_cal\n",
    "            # p1.plot(bins_cal, hist_norm, ds='steps', c='b', lw=1,\n",
    "            p1.semilogy(bins_cal, hist_norm, ds='steps', c='b', lw=1,\n",
    "                    label=f'E = {lin_cal:.3f}*{et}')\n",
    "\n",
    "            # compute best-guess location of all peaks, assuming rough calibration\n",
    "            cal_maxes = lin_cal * maxes[:, 0]\n",
    "            all_pks = np.concatenate((exp_pks, tst_pks))\n",
    "            raw_guesses = []\n",
    "            for pk in all_pks:\n",
    "\n",
    "                imatch = np.isclose(cal_maxes, pk, atol=config['mp_tol'])\n",
    "                if imatch.any():\n",
    "                    print(pk, cal_maxes[imatch], maxes[:,0][imatch])\n",
    "                    raw_guesses.append([pk, maxes[:,0][imatch][0]])\n",
    "\n",
    "            if len(raw_guesses) != 0:\n",
    "                rg = np.asarray(raw_guesses)\n",
    "                rg = rg[rg[:,0].argsort()] # sort by energy\n",
    "                cmap = plt.cm.get_cmap('jet', len(rg))\n",
    "                for i, epk in enumerate(rg):\n",
    "                    idx_nearest = (np.abs(bins_cal - epk[0])).argmin()\n",
    "                    cts_nearest = hist_norm[idx_nearest]\n",
    "                    p1.plot(epk[0], cts_nearest, '.r', c=cmap(i),\n",
    "                            label=f'{epk[0]:.1f} keV')\n",
    "                print('raw pk locations:\\n', rg)\n",
    "\n",
    "            p1.set_xlabel(f'{et}, pass-1 cal', ha='right', x=1)\n",
    "            p1.set_ylabel(f'cts/s, {xpb} kev/bin', ha='right', y=1)\n",
    "            p1.legend(fontsize=10)\n",
    "\n",
    "            if config['batch_mode']:\n",
    "                plt.savefig(f'./plots/energy_cal/peakdet_{et}_run{run}_clo{cyclo}_chi{cychi}.pdf')\n",
    "            else:\n",
    "                plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        pd_results[f'{et}_calpass'] = mp_success\n",
    "        pd_results[f'{et}_runtime'] = runtime_min\n",
    "        pd_results[f'{et}_pol0'] = 0 \n",
    "        pd_results[f'{et}_pol1'] = lin_cal\n",
    "        pd_results[f'{et}_cyclo'] = cyclo\n",
    "        pd_results[f'{et}_cychi'] = cychi\n",
    "\n",
    "    return pd.Series(pd_results)\n",
    "\n",
    "\n",
    "def match_peaks(maxes, exp_pks, tst_pks, mode='first', ene_tol=10):\n",
    "    \"\"\"\n",
    "    modes:\n",
    "    - 'first' : pin the first expected peak, search for the first test peak\n",
    "    - 'ratio' : compute ratio match\n",
    "    \"\"\"\n",
    "    print('running autopeak matching.  mode is:', mode)\n",
    "    \n",
    "    if mode == 'first':\n",
    "\n",
    "        # set expected and test peak\n",
    "        exp_pk, tst_pk = exp_pks[0], tst_pks[0]\n",
    "        print(f'Pinning {exp_pk} looking for {tst_pk}, tolerance: {ene_tol} keV')\n",
    "\n",
    "        # loop over raw peaks, apply a linear cal, and see if there\n",
    "        # is a raw peak near the test location, within an energy tolerance\n",
    "        lin_cals = []\n",
    "        for xpk in maxes[:,0]:\n",
    "            lin_cal = exp_pk / xpk\n",
    "            cal_maxes = lin_cal * maxes[:,0]\n",
    "            imatch = np.isclose(cal_maxes, tst_pk, atol=ene_tol)\n",
    "            if imatch.any():\n",
    "                lin_cals.append(lin_cal)\n",
    "        lin_cals = sorted(lin_cals)\n",
    "\n",
    "        if len(lin_cals) == 0:\n",
    "            print('Found no matches!')\n",
    "            return 1, False\n",
    "        elif len(lin_cals) > 1:\n",
    "            print('Warning, found multiple matches. Using first one...')\n",
    "            print(lin_cals)\n",
    "            # exit()\n",
    "\n",
    "        # first pass calibration constant\n",
    "        return lin_cals[0], True\n",
    "\n",
    "    elif mode == 'ratio':\n",
    "        \"\"\"\n",
    "        # NOTE: maybe we can improve on \"first\" mode by computing all\n",
    "        # permutations and returning a calibration constant that 'averages'\n",
    "        # between the most correct ones.\n",
    "\n",
    "        Uses a peak matching algorithm based on finding ratios of uncalibrated (u)\n",
    "        and \"true, keV-scale\" (e) energies.\n",
    "        We run peakdet to find the maxima in the spectrum, then compute all ratios:\n",
    "            - e1/e2, u1/u2, ..., u29/u30 etc.\n",
    "        We find the subset of uncalibrated ratios (u7/u8, ... etc) that match the\n",
    "        \"true\" ratios, and compute a calibration constant for each.\n",
    "\n",
    "        Then for each uncalibrated ratio, we assume it to be true, then loop over\n",
    "        the expected peak positions.\n",
    "\n",
    "        We shift the uncalibrated peaks so that the true peak would be very close\n",
    "        to 0, and calculate its distance from 0.  The \"true\" calibration constant\n",
    "        will minimize this value for all ratios, and this is the one we select.\n",
    "        \"\"\"\n",
    "\n",
    "        # run peakdet to identify the uncalibrated maxima\n",
    "        maxes, mins = pu.peakdet(h, pk_thresh, b)\n",
    "        umaxes = np.array(sorted([x[0] for x in maxes], reverse=True))\n",
    "\n",
    "        # compute all ratios\n",
    "        ecom = [c for c in it.combinations(epeaks, 2)]\n",
    "        ucom = [c for c in it.combinations(umaxes, 2)]\n",
    "        eratios = np.array([x[0] / x[1] for x in ecom]) # assumes x[0] > x[1]\n",
    "        uratios = np.array([x[0] / x[1] for x in ucom])\n",
    "\n",
    "        # match peaks to true energies\n",
    "        cals = {}\n",
    "        for i, er in enumerate(eratios):\n",
    "\n",
    "            umatch = np.where( np.isclose(uratios, er, rtol=match_thresh) )\n",
    "            e1, e2 = ecom[i][0], ecom[i][1]\n",
    "            if test:\n",
    "                print(f\"\\nratio {i} -- e1 {e1:.0f}  e2 {e2:.0f} -- {er:.3f}\")\n",
    "\n",
    "            if len(umatch[0]) == 0:\n",
    "                continue\n",
    "\n",
    "            caldists = []\n",
    "            for ij, j in enumerate(umatch[0]):\n",
    "                u1, u2 = ucom[j][0], ucom[j][1]\n",
    "                cal = (e2 - e1) / (u2 - u1)\n",
    "                cal_maxes = cal * umaxes\n",
    "\n",
    "                # shift peaks by the amount we would expect if this const were true.\n",
    "                # compute the distance (in \"keV\") of the peak that minimizes this.\n",
    "                dist = 0\n",
    "                for e_true in epeaks:\n",
    "                    idx = np.abs(cal_maxes - e_true).argmin()\n",
    "                    dist += np.abs(cal_maxes[idx] - e_true)\n",
    "                caldists.append([cal, dist])\n",
    "\n",
    "                if test:\n",
    "                    dev = er - uratios[j] # set by match_thresh parameter\n",
    "                    print(f\"{ij}  {u1:-5.0f}  {u2:-5.0f}  {dev:-7.3f}  {cal:-5.2f}\")\n",
    "\n",
    "            # get the cal ratio with the smallest total dist\n",
    "            caldists = np.array(caldists)\n",
    "            imin = caldists[:,1].argmin()\n",
    "            cals[i] = caldists[imin, :]\n",
    "\n",
    "            if test:\n",
    "                print(f\"best: {imin}  {caldists[imin, 0]:.4f}  {caldists[imin, 1]:.4f}\")\n",
    "\n",
    "        if test:\n",
    "            print(\"\\nSummary:\")\n",
    "            for ipk in cals:\n",
    "                e1, e2 = ecom[ipk][0], ecom[ipk][1]\n",
    "                print(f\"{ipk}  {e1:-6.1f}  {e2:-6.1f}  cal {cals[ipk][0]:.5f}\")\n",
    "\n",
    "        # get first-pass const for this DataSet\n",
    "        cal_vals = np.array([c[1][0] for c in cals.items()])\n",
    "        ds_cal = np.median(cal_vals)\n",
    "        ds_std = np.std(cal_vals)\n",
    "        print(f\"Pass-1 cal for {etype}: {ds_cal:.5e} pm {ds_std:.5e}\")\n",
    "    \n",
    "    # if we get here, we failed\n",
    "    print('Warning, peakdet has failed.')\n",
    "    return None, False\n",
    "\n",
    "\n",
    "def peakdet_input(df_group, config):\n",
    "    \"\"\"\n",
    "    $ ./energy_cal.py -q 'whatever' -pi [input_id] [-p]\n",
    "    Instead of using the automatic peakdet algorithm, compute the first-guess\n",
    "    calibration constant from an input file.\n",
    "    \"\"\"\n",
    "    # load data and compute runtime\n",
    "    dsp_list = config['lh5_dir'] + df_group['dsp_path'] + '/' + df_group['dsp_file']\n",
    "    edata = lh5.load_nda(dsp_list, config['rawe'], config['input_table'], verbose=False)\n",
    "    runtime_min = df_group['runtime'].sum()\n",
    "    run = int(df_group.run.iloc[0])\n",
    "    cyclo, cychi = df_group.cycle.iloc[0], df_group.cycle.iloc[-1]\n",
    "    print(f'  Runtime: {runtime_min:.1f} min.  Calibrating:', [f'{et}:{len(ev)} events' for et, ev in edata.items()])\n",
    "    \n",
    "    # loop over energy estimators of interest\n",
    "    pd_results = {}\n",
    "    for et in config['rawe']:\n",
    "\n",
    "        # get histogram, error, normalize by runtime, and derivative\n",
    "        xlo, xhi, xpb = config['init_vals'][et]['raw_range']\n",
    "        hist, bins, var = pgh.get_hist(edata[et], range=(xlo, xhi), dx=xpb)\n",
    "        hist_norm = np.divide(hist, runtime_min * 60)\n",
    "        hist_err = np.array([np.sqrt(hbin / (runtime_min * 60)) for hbin in hist])\n",
    "\n",
    "        # load the input peaks\n",
    "        inp_id = config['input_id'] # string id, like 002\n",
    "        with open(config['input_peaks']) as f:\n",
    "            pk_inputs = json.load(f)\n",
    "        # pprint(pk_inputs)\n",
    "        pk_list = {k:v for k,v in pk_inputs[inp_id][et].items()}\n",
    "        yv = [pk_list[k][0] for k in pk_list] # true peaks (keV)\n",
    "        xv_input = [pk_list[k][1] for k in pk_list] # raw peaks (uncalib.)\n",
    "        # pprint(pk_list)\n",
    "        \n",
    "        # To make the input_peaks method more robust, add a step to refine\n",
    "        # the input peak guess that can catch small changes in gain.\n",
    "        # For each peak, select the maximum bin within 3% of the input\n",
    "        # raw energy value.  It's hard to make this window larger if you're \n",
    "        # using calibration peaks very close together (like 583 and 609).\n",
    "        xv_tuned = []\n",
    "        for rpk in xv_input:\n",
    "            winlo, winhi = rpk * (1 - 0.03), rpk * (1 + 0.03)\n",
    "            idx = np.where((bins >= winlo) & (bins <= winhi))\n",
    "            ilo = idx[0][0]\n",
    "            imax = np.argmax(hist_norm[idx])\n",
    "            ipk = ilo + imax\n",
    "            xval_adj = bins[ipk]\n",
    "            xv_tuned.append(xval_adj)\n",
    "        xv = xv_tuned\n",
    "        \n",
    "        # run polyfit (pass-1 fit is simple)\n",
    "        pol = config['pol'][0]\n",
    "        pfit = np.polyfit(xv, yv, pol) # p2, p1, p0\n",
    "        \n",
    "        # save results for this energy estimator\n",
    "        pd_results[f'{et}_calpass'] = True\n",
    "        pd_results[f'{et}_runtime'] = runtime_min\n",
    "        pd_results[f'{et}_cyclo'] = cyclo\n",
    "        pd_results[f'{et}_cychi'] = cychi\n",
    "        for i, p in enumerate(np.flip(pfit)): # p0, p1, p2\n",
    "            pd_results[f'{et}_pol{i}'] = p\n",
    "\n",
    "        if config['show_plot']:\n",
    "            \n",
    "            # plot uncalibrated and calibrated energy spectrum, w/ maxima\n",
    "            fig, (p0, p1) = plt.subplots(2, 1, figsize=(8, 8))\n",
    "            \n",
    "            # 1. show spectrum and input peaks\n",
    "            p0.semilogy(bins[1:], hist_norm, 'b', ds='steps', lw=1)\n",
    "            \n",
    "            p0.plot(np.nan, np.nan, '-w', label=f'Run {run}, cyc {cyclo}--{cychi}')\n",
    "            \n",
    "            cmap = plt.cm.get_cmap('jet', len(pk_list))\n",
    "            for i in range(len(xv)):\n",
    "                rpk = xv[i]\n",
    "                idx = (np.abs(bins - rpk)).argmin()\n",
    "                p0.plot(rpk, hist_norm[idx], 'v', ms=10, c=cmap(i),\n",
    "                        label=f'{yv[i]} : {rpk:.0f}')\n",
    "            \n",
    "            p0.set_xlabel(f'{et} (uncal)', ha='right', x=1)\n",
    "            p0.set_ylabel(f'Counts / min / {xpb:.1f} keV', ha='right', y=1)\n",
    "            p0.legend(fontsize=10)\n",
    "            p0.set_ylim(1e-4)\n",
    "            \n",
    "            # 2: show the calibration curve fit result\n",
    "            p1.plot(np.nan, np.nan, '-w', label=f'Run {run}, cyc {cyclo}--{cychi}')\n",
    "            \n",
    "            p1.plot(xv, yv, '.k')\n",
    "            \n",
    "            polfunc = np.poly1d(pfit) # handy numpy polynomial function\n",
    "            yfit = polfunc(xv)\n",
    "            pol_label = '  '.join([f'p{i} : {ene:.2e}' for i, ene in enumerate(pfit[::-1])])\n",
    "            p1.plot(xv, yfit, '-r', lw=2, label=pol_label)\n",
    "            \n",
    "            p1.set_xlabel(f'{et} (uncal)', ha='right', x=1)\n",
    "            p1.set_ylabel('Energy (keV)', ha='right', y=1)\n",
    "            p1.legend(fontsize=10)\n",
    "            \n",
    "            if config['batch_mode']:\n",
    "                plt.savefig(f'./plots/energy_cal/peakinput_{et}_run{run}_clo{cyclo}_chi{cychi}.pdf')\n",
    "            else:\n",
    "                plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "    return pd.Series(pd_results)\n",
    "\n",
    "\n",
    "def run_peakfit(dg, config, db_ecal):\n",
    "    \"\"\"\n",
    "    $ ./energy_cal.py -q 'query' -pf [-pi KEY] [-p : show plot]\n",
    "    \n",
    "    Using the first guess calibration from peakdet, fit each peak of interest\n",
    "    and compute the calibration and resolution curves.\n",
    "    \"\"\"\n",
    "    gb = dg.fileDB.groupby(config['gb_cols'])\n",
    "    runs = dg.fileDB.run.unique()\n",
    "    cyclo, cychi = dg.fileDB.cycle.iloc[0], dg.fileDB.cycle.iloc[-1]\n",
    "    print(f'Running peakfit, runs {runs}, cycles {cyclo}--{cychi}')\n",
    "    \n",
    "    result = gb.apply(peakfit, *[config, db_ecal])\n",
    "    \n",
    "    def parse_results(df_run):\n",
    "        \"\"\"\n",
    "        for each run, compute entries for each energy estimator for TinyDB\n",
    "        \"\"\"\n",
    "        run = int(df_run.index[0])\n",
    "\n",
    "        for epar in config['rawe']:\n",
    "            \n",
    "            # format output\n",
    "            epar_cols = [r for r in df_run.columns if epar in r]\n",
    "            df_epar = df_run[epar_cols].copy()\n",
    "            df_epar.rename(columns={c:c.split('_')[-1] for c in epar_cols},\n",
    "                           inplace=True)\n",
    "            df_epar.reset_index(inplace=True)\n",
    "            \n",
    "            if 'cycle' in df_epar.columns:\n",
    "                # this is redundant with cyclo and cychi\n",
    "                df_epar.drop('cycle', 1, inplace=True)\n",
    "            cyclo, cychi = df_epar.iloc[0][['cyclo','cychi']]\n",
    "            \n",
    "            tb_name = f'peakfit_{epar}'\n",
    "            print('Results:', tb_name)\n",
    "            print(f'Run {run}  cycles {cyclo}--{cychi}')\n",
    "            print(df_epar)\n",
    "            \n",
    "            # this is in-memory, no write to file yet\n",
    "            table = db_ecal.table(tb_name)\n",
    "            q = db.Query()\n",
    "            for i, row in df_epar.iterrows():\n",
    "                que = ((q.run==row.run) & (q.cyclo==row.cyclo) & (q.cychi==row.cychi))\n",
    "                table.upsert(row.to_dict(), que)\n",
    "\n",
    "    # parse the results\n",
    "    result.groupby(['run']).apply(parse_results)\n",
    "\n",
    "    if not config['write_db']:\n",
    "        print('Done. ecalDB write mode not set (-w option)')\n",
    "        return\n",
    "\n",
    "    # show in-memory state and then write to file\n",
    "    # pprint(db_ecal.storage.read())\n",
    "    print('Writing results to ecalDB.')\n",
    "    pmd.write_pretty(db_ecal.storage.read(), config['ecaldb'])\n",
    "\n",
    "\n",
    "def peakfit(df_group, config, db_ecal):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    $ ./energy_cal.py -q 'run==117' -pf [-pi 002 : use peakinput] [-p : show plot]\n",
    "    \"\"\"\n",
    "    # choose the mode of peakdet to look up constants from \n",
    "    if 'input_id' in config.keys():\n",
    "        pol = config['pol'][0]\n",
    "        print('  Using 1st-pass constants from peakdet_input')\n",
    "        input_peaks = True\n",
    "    else:\n",
    "        print('  Using 1st-pass constants from peakdet_auto')\n",
    "        input_peaks = False\n",
    "        pol = 1 # and p0==0 always\n",
    "        \n",
    "    run = int(df_group.run.iloc[0])\n",
    "    cyclo, cychi = df_group.cycle.iloc[0], df_group.cycle.iloc[-1]    \n",
    "    \n",
    "    gb_run = df_group['run'].unique()\n",
    "    if len(gb_run) > 1:\n",
    "        print(\"Multi-run queries aren't supported yet, sorry!\")\n",
    "        exit()\n",
    "        \n",
    "    # load data and compute runtime\n",
    "    dsp_list = config['lh5_dir'] + df_group['dsp_path'] + '/' + df_group['dsp_file']\n",
    "    raw_data = lh5.load_nda(dsp_list, config['rawe'], config['input_table'], verbose=False)\n",
    "    runtime_min = df_group['runtime'].sum()\n",
    "    print(f'  Runtime: {runtime_min:.1f} min.  Calibrating:', [f'{et}:{len(ev)} events' for et, ev in raw_data.items()])\n",
    "    print(f'  Fitting to:', config['fit_func'])\n",
    "\n",
    "    # get list of peaks to look for\n",
    "    epeaks = config['expected_peaks'] + config['test_peaks']\n",
    "    epeaks = np.array(sorted(epeaks))\n",
    "    \n",
    "    # loop over energy estimators of interest\n",
    "    pf_results = {}\n",
    "    for et in config['rawe']:\n",
    "\n",
    "        # load first-guess calibration constants from tables in the ecalDB\n",
    "        # convention for p_i : p0  +  p1 * x  +  p2 * x**2  +  ...\n",
    "        tb_name = f'peakinp_{et}' if input_peaks else f'peakdet_{et}'\n",
    "        db_table = db_ecal.table(tb_name).all()\n",
    "        df_cal = pd.DataFrame(db_table)\n",
    "        if len(df_cal)==0:\n",
    "            print(\"Error, couldn't load cal constants for table:\", tb_name)\n",
    "            print(\"Try running: ./energy_cal.py -q '[query]' -s\", tb_name)\n",
    "            exit()\n",
    "\n",
    "        que = f'run=={run} and cyclo=={cyclo} and cychi=={cychi}'\n",
    "        p1cal = df_cal.query(que)\n",
    "        if len(p1cal) != 1:\n",
    "            print(f\"Can't load a unique set of cal constants!\\n  Full cal DF, '{tb_name}':\")\n",
    "            print(df_cal)\n",
    "            print('Result of query:', que)\n",
    "            print(p1cal)\n",
    "            exit()\n",
    "        \n",
    "        # get first-guess coefficients (p2, p1, p0)\n",
    "        # NOTE: np.polyfit expects the coefficients with highest order first\n",
    "        cal_pars_init = [p1cal[f'pol{p}'].iloc[0] for p in range(pol, -1, -1)]\n",
    "        print(f'pass 0 constants:', cal_pars_init)\n",
    "        \n",
    "        # -- compute calibration curve -- \n",
    "        # NOTE: to see the effect of the 2nd and 3rd steps, try commenting them out!\n",
    "        \n",
    "        # 1. use first guess to float peak positions, and compute new initial\n",
    "        # guesses for the locations of the raw peaks\n",
    "        f1 = fit_peaks(epeaks, cal_pars_init, raw_data[et], runtime_min, \n",
    "                       ff_name = config['fit_func'], show_plot = False, \n",
    "                       batch = config['batch_mode'])\n",
    "        df_fits = pd.DataFrame(f1).T \n",
    "        \n",
    "        pfit, pcov = np.polyfit(df_fits['mu_raw'], df_fits['epk'], config['pol'][0], cov=True)\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        \n",
    "        # print(\"part 1 constants \", pfit)\n",
    "        # print(\"part 1 dataframe:\")\n",
    "        # print(df_fits)\n",
    "        \n",
    "        # 2. the new guess of the raw peak location might still be wrong.\n",
    "        # so float peak positions a second time, using a calibration constant\n",
    "        # of unity.  this should give a polynomial which can be used to \n",
    "        # correct the first one.\n",
    "        f2 = fit_peaks(df_fits['mu_raw'], [0, 1, 0], raw_data[et], runtime_min,\n",
    "                       range = config['init_vals'][et]['raw_range'],\n",
    "                       ff_name = config['fit_func'], show_plot = False, \n",
    "                       batch = config['batch_mode'])\n",
    "        df2 = pd.DataFrame(f2).T\n",
    "        pfit, pcov = np.polyfit(df2['epk'], df2['mu'], config['pol'][0], cov=True)\n",
    "        pfunc = np.poly1d(pfit)\n",
    "        df2['mu_new'] = pfunc(df2['mu_raw']) \n",
    "        \n",
    "        # print(\"part 2 constants:\", pfit)\n",
    "        # print(\"part 2 dataframe:\")\n",
    "        # print(df2)\n",
    "        \n",
    "        # 3. using the final \"best guess\" locations of the raw peaks,\n",
    "        # compute the final calibration curve, and float the peaks again\n",
    "        # to save results on the FWHM's, etc.\n",
    "        \n",
    "        pfit, pcov = np.polyfit(df2['mu_new'], df_fits['epk'], config['pol'][0], cov=True)\n",
    "        f3 = fit_peaks(epeaks, pfit, raw_data[et], runtime_min,\n",
    "                       ff_name = config['fit_func'], show_plot = False,\n",
    "                       batch = config['batch_mode'])\n",
    "        df_fit3 = pd.DataFrame(f3).T\n",
    "        pfit, pcov = np.polyfit(df_fit3['mu_raw'], df_fits['epk'], config['pol'][0], cov=True)\n",
    "        \n",
    "        print(\"part 3 constants:\", pfit)\n",
    "        print(\"part 3 dataframe:\")\n",
    "        print(df_fits)\n",
    "        df_fits = df_fit3\n",
    "        p_err_cal = np.sqrt(np.diag(pcov))\n",
    "        \n",
    "        # ---- end calibration curve calculation ----\n",
    "        \n",
    "        # compute the difference between lit and measured values\n",
    "        pfunc = np.poly1d(pfit)\n",
    "        cal_data = pfunc(raw_data[et])\n",
    "        cal_peaks = pfunc(df_fits['mu_raw'])\n",
    "        df_fits['residual'] = df_fits['epk'] - df_fits['mu']\n",
    "        res_uncertainty = df_fits['mu_err']\n",
    "        \n",
    "        cp = [f'p{i} {cp:.4e} ' for i, cp in enumerate(pfit[::-1])]\n",
    "        print(f'  Peakfit outputs:', ' '.join(cp))\n",
    "        print(df_fits)\n",
    "        # exit()\n",
    "        \n",
    "        # TODO: save this output to a SEPARATE output file (don't muck up pf_results,\n",
    "        # which is intended to be just for the constants p0, p1, p2 ... etc.\n",
    "        # print(df_fits)\n",
    "\n",
    "        # fit fwhm vs. energy\n",
    "        # FWHM(E) = sqrt(A_noise^2 + A_fano^2 * E + A_qcol^2 E^2)\n",
    "        # Ref: Eq. 3 of https://arxiv.org/abs/1902.02299\n",
    "        # TODO: fix error handling\n",
    "        def sqrt_fwhm(x, a_n, a_f, a_c):\n",
    "            return np.sqrt(a_n**2 + a_f**2 * x + a_c**2 * x**2)\n",
    "        p_guess = [0.3, 0.05, 0.001]\n",
    "        sig_fit, p_cov = curve_fit(sqrt_fwhm, df_fits['mu'], df_fits['fwhm'],\n",
    "                                 p0=p_guess)#, sigma = np.sqrt(h), absolute_sigma=True)\n",
    "        p_err = np.sqrt(np.diag(p_cov))\n",
    "\n",
    "        # show a split figure with calibrated spectrum + used peaks on top,\n",
    "        # and calib.function and resolution vs. energy on bottom\n",
    "        if config['show_plot']:\n",
    "            \n",
    "            fig = plt.figure(figsize=(8,8))\n",
    "            p1 = plt.subplot(2, 1, 1) # calibrated spectrum\n",
    "            p2 = plt.subplot(2, 2, 3) # resolution vs energy\n",
    "            p3 = plt.subplot(2, 2, 4) # fit_mu vs energy\n",
    "            \n",
    "            # 1. show calibrated spectrum with gamma lines\n",
    "            # get histogram (cts / keV / d)\n",
    "            xlo, xhi, xpb = config['cal_range']\n",
    "            hist, bins, _ = pgh.get_hist(cal_data, range=(xlo, xhi), dx=xpb)\n",
    "            hist_norm = np.divide(hist, runtime_min * 60 * xpb)\n",
    "\n",
    "            # show peaks\n",
    "            cmap = plt.cm.get_cmap('brg', len(df_fits)+1)\n",
    "            for i, row in df_fits.iterrows():\n",
    "                \n",
    "                # get a pretty label for the isotope\n",
    "                lbl = config['pks'][str(row['epk'])]\n",
    "                iso = ''.join(r for r in re.findall('[0-9]+', lbl))\n",
    "                ele = ''.join(r for r in re.findall('[a-z]', lbl, re.I))\n",
    "                pk_lbl = r'$^{%s}$%s' % (iso, ele)\n",
    "\n",
    "                pk_diff = row['epk'] - row['mu']\n",
    "                p1.axvline(row['epk'], ls='--', c=cmap(i), lw=1,\n",
    "                            label=f\"{pk_lbl}, {row['epk']:.1f}:   {row['mu']:.1f}  ({pk_diff:.3f}) keV\")\n",
    "\n",
    "            cp = [f'p{i} {cp:.3e} ' for i, cp in enumerate(pfit[::-1])]\n",
    "            p1.plot(np.nan, np.nan, c='w', label=' '.join(cp))\n",
    "\n",
    "            p1.semilogy(bins[1:], hist_norm, ds='steps', c='b', lw=1)\n",
    "            p1.set_ylim(1e-4)\n",
    "            p1.set_xlabel('Energy (keV)', ha='right', x=1)\n",
    "            p1.set_ylabel('cts / s / keV', ha='right', y=1)\n",
    "            p1.legend(fontsize=7)\n",
    "\n",
    "            # 2. resolution vs. energy\n",
    "            \n",
    "            # TODO: add fwhm errorbar\n",
    "            x_fit = np.arange(xlo, xhi, xpb)\n",
    "            y_init = sqrt_fwhm(x_fit, *p_guess)\n",
    "            # p1.plot(x_fit, y_init, '-', lw=1, c='orange', label='guess')\n",
    "\n",
    "            y_fit = sqrt_fwhm(x_fit, *sig_fit)\n",
    "            a_n, a_f, a_c = sig_fit\n",
    "            fit_label = r'$\\sqrt{(%.2f)^2 + (%.3f)^2 E + (%.4f)^2  E^2}$' % (a_n, a_f, a_c)\n",
    "            p2.plot(x_fit, y_fit, '-r', lw=1, label=f'fit: {fit_label}')\n",
    "\n",
    "            p2.errorbar(df_fits.mu, df_fits.fwhm, \n",
    "                        yerr = df_fits.fwhm_err, \n",
    "                        c='k', ms=5, linewidth=1, \n",
    "                        fmt='.', capsize=1)\n",
    "\n",
    "            p2.set_xlabel('Energy (keV)', ha='right', x=1)\n",
    "            p2.set_ylabel('FWHM (keV)', ha='right', y=1)\n",
    "            p2.legend(fontsize=11)\n",
    "            \n",
    "            # 3. fit_mu vs. energy\n",
    "            p3.errorbar(df_fits.epk, df_fits.epk - df_fits.mu, \n",
    "                        yerr = df_fits.mu_err, \n",
    "                        c='k', ms=5, linewidth=1, \n",
    "                        fmt='.', capsize=1,\n",
    "                        label=r'$E_{true}$ - $E_{fit}$')\n",
    "            \n",
    "            p3.set_xlabel('Energy (keV)', ha='right', x=1)\n",
    "            p3.set_ylabel('Residual (keV)', ha='right', y=1)\n",
    "            p3.legend(fontsize=15)\n",
    "\n",
    "            if config['batch_mode']:\n",
    "                plt.savefig(f'./plots/energy_cal/peakfit_{et}_run{run}_clo{cyclo}_chi{cychi}.pdf')\n",
    "            else:\n",
    "                plt.show()\n",
    "            plt.close('all')\n",
    "\n",
    "        # fill in the peakfit results and return\n",
    "        \n",
    "        # cycle range\n",
    "        pf_results[f'{et}_cyclo'] = cyclo\n",
    "        pf_results[f'{et}_cychi'] = cychi\n",
    "        \n",
    "        # energy calibration constants \n",
    "        for i, p in enumerate(pfit[::-1]): # remember to flip the coeffs!\n",
    "            pf_results[f'{et}_cal{i}'] = p\n",
    "\n",
    "        # uncertainties in cal constants\n",
    "        for i, pe in enumerate(p_err_cal[::-1]):\n",
    "            pf_results[f'{et}_unc{i}'] = pe\n",
    "        \n",
    "        # resolution curve parameters\n",
    "        pf_results[f'{et}_Anoise'] = sig_fit[0]\n",
    "        pf_results[f'{et}_Afano'] = sig_fit[1]\n",
    "        pf_results[f'{et}_Aqcol'] = sig_fit[2]\n",
    "        pf_results[f'{et}_runtime'] = runtime_min\n",
    "        \n",
    "    return pd.Series(pf_results)\n",
    "\n",
    "\n",
    "def fit_peaks(epeaks, cal_pars, raw_data, runtime_min, range=[0, 3000, 5], ff_name='gauss_step', show_plot=True, batch=False):\n",
    "    \"\"\"\n",
    "    Routine for sequential fit of peaks in a raw energy spectrum.\n",
    "    \n",
    "    Inputs: \n",
    "    - epeaks: list of peak energies to calibrate, e.g. [1460, 2615, ...]\n",
    "    - cal_pars: results from peakdet for the first estimate of the calibration:\n",
    "        cal_data = p0  +  p1 * raw_data  +  p2 * raw_data**2  +  ...\n",
    "    - raw_data: numpy array of uncalibrated data.  The array is needed instead \n",
    "        of a histogram because this routine tries to optimize the binning\n",
    "        around each peak.\n",
    "    - runtime_min : this is used to normalize spectra to cts/min, which helps a\n",
    "        lot to compute initial guesses for fit functions.\n",
    "    - range : [xlo, xhi, xpb]\n",
    "    \n",
    "    Returns a dict, 'fit_results', which is easily convertible to DataFrame.\n",
    "    \"\"\"\n",
    "    # compute calibrated energy.\n",
    "    # scale the raw data s/t the peaks in 'epeaks' are decent initial guesses\n",
    "    pfunc = np.poly1d(cal_pars)\n",
    "    cal_data = pfunc(raw_data)\n",
    "    \n",
    "    # quick spectrum check (check that the input calibration parameters are in the ballpark)\n",
    "    if show_plot:\n",
    "        xlo, xhi, xpb = range\n",
    "        hist, bins, _ = pgh.get_hist(cal_data, range=(xlo, xhi), dx=xpb)\n",
    "        hist_norm = np.divide(hist, runtime_min * 60 * xpb)\n",
    "        plt.semilogy(bins[1:], hist_norm, ds='steps', c='b', lw=1)\n",
    "        if batch:\n",
    "            plt.savefig(f'./plots/energy_cal/peakfit_test.png')\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.cla()\n",
    "    \n",
    "    # loop over peak energies\n",
    "    fit_results = {}\n",
    "    for ie, epk in enumerate(epeaks):\n",
    "        \n",
    "        # adjust the window.  resolution goes as roughly sqrt(energy)\n",
    "        window = np.sqrt(epk)\n",
    "        xlo, xhi = epk - window / 2, epk + window / 2\n",
    "        nbins = int(window) * 3 # todo, make this get smaller w/ inc energy\n",
    "        xpb = (xhi - xlo) / nbins\n",
    "        \n",
    "        if show_plot:\n",
    "            print(f'Fitting peak at {epk:6.1f} keV.  xlo {xlo:6.1f}  xhi {xhi:6.1f}  xpb {xpb:.3f}  nbins {nbins}')\n",
    "        \n",
    "        # get histogram, error, normalize by runtime\n",
    "        pk_data = cal_data[(cal_data >= xlo) & (cal_data <= xhi)]\n",
    "        hist, bins, _ = pgh.get_hist(pk_data, range=(xlo, xhi), dx=xpb)\n",
    "        hist_norm = np.divide(hist, runtime_min * 60)\n",
    "        hist_var = np.array([np.sqrt(h / (runtime_min * 60)) for h in hist])\n",
    "        \n",
    "        # estimate left and right sideband locations\n",
    "        ibkg_lo, ibkg_hi = int(nbins * 0.2), int(nbins * 0.8)\n",
    "        bkg0 = np.mean(hist_norm[ :ibkg_lo])\n",
    "        bkg0_hi = np.mean(hist_norm[ibkg_hi:])\n",
    "        b, h = bins[1:], hist_norm - bkg0\n",
    "        \n",
    "        # default: gaussian fit + step function : a, mu, sigma, bkg, step\n",
    "        if ff_name == 'gauss_step':\n",
    "            \n",
    "            fit_func = pgf.gauss_step    \n",
    "\n",
    "            # set robust initial guesses\n",
    "            step0 = bkg0 - bkg0_hi\n",
    "            imax = np.argmax(h)\n",
    "            ix_upr = np.where((b > b[imax]) & (h <= np.amax(h)/2))\n",
    "            ix_bot = np.where((b < b[imax]) & (h <= np.amax(h)/2))\n",
    "        \n",
    "            if show_plot:\n",
    "                # print(b[imax], np.amax(h)/2)\n",
    "                # print(b.shape, h.shape)\n",
    "                # print('ix_upr', ix_upr)\n",
    "                # print('b', b)\n",
    "                # print('b[ix_upr]', b[ix_upr])\n",
    "                # print('ix_bot', ix_bot)\n",
    "                # print('LEN IXBOT', len(ix_bot[0]))\n",
    "                plt.close()\n",
    "                plt.plot(b, h, c='b', ds='steps', lw=2)\n",
    "                plt.xlabel('pass-1 energy (kev)', ha='right', x=1)\n",
    "                plt.show()\n",
    "\n",
    "            if len(ix_upr[0]) == 0 or len(ix_bot[0]) == 0:\n",
    "                print(\"Error, couldn't set intitial guesses for peak. Maybe check your input calibration constants and set show_plot=True\")\n",
    "                exit()\n",
    "\n",
    "            upr_half = b[ix_upr][0]\n",
    "            bot_half = b[ix_bot][-1]\n",
    "            fwhm0 = upr_half - bot_half\n",
    "            sig0 = fwhm0 / 2.355\n",
    "            amp0 = np.amax(h) * fwhm0\n",
    "            p_init = [amp0, bins[imax], sig0, bkg0, step0]\n",
    "\n",
    "            p_fit, p_cov = pgf.fit_hist(fit_func, hist_norm, bins, \n",
    "                                        var=hist_var, guess=p_init)\n",
    "            p_err = np.sqrt(np.diag(p_cov))\n",
    "            fwhm = p_fit[2] * 2.355\n",
    "            fwhm_err = p_err[2] * 2.355\n",
    "            mu_err = p_err[1] \n",
    "\n",
    "            fit_results[ie] = {\n",
    "                'epk':epk, 'mu':p_fit[1], 'mu0':bins[imax], 'fwhm':p_fit[2]*2.355,\n",
    "                'sig':p_fit[2], 'amp':p_fit[0], 'bkg':p_fit[3], \n",
    "                'fwhm_err':fwhm_err, 'mu_err':mu_err\n",
    "                }\n",
    "\n",
    "        # peakshape : mu, sigma, hstep, htail, tau, bg0, amp\n",
    "        # this requires higher stats, doesn't work as well for smaller peaks\n",
    "        elif ff_name == 'peakshape':\n",
    "            \n",
    "            fit_func = pgf.radford_peak\n",
    "            \n",
    "            # set robust initial guesses\n",
    "            step0 = bkg0 - bkg0_hi\n",
    "            imax = np.argmax(h)\n",
    "            upr_half = b[np.where((b > b[imax]) & (h <= np.amax(h)/2))][0]\n",
    "            bot_half = b[np.where((b < b[imax]) & (h <= np.amax(h)/2))][-1]\n",
    "            fwhm0 = upr_half - bot_half\n",
    "            sig0 = fwhm0 / 2.355\n",
    "            amp0 = np.amax(h) * fwhm0\n",
    "            htail, tau = 0.1, 10 # TODO: find a way to guess these\n",
    "            p_init = [bins[imax], sig0, step0, htail, tau, bkg0, amp0]\n",
    "            \n",
    "            p_fit, p_cov = pgf.fit_hist(fit_func, hist_norm, bins,\n",
    "                                        var=hist_var, guess=p_init)\n",
    "            p_err = np.sqrt(np.diag(p_cov))\n",
    "            fwhm = p_fit[1] * 2.355\n",
    "            fwhm_err = p_err[1] * 2.355 \n",
    "            mu_err = p_err[0] \n",
    "            \n",
    "            fit_results[ie] = {\n",
    "                'epk':epk,\n",
    "                'mu':p_fit[0], 'fwhm':p_fit[1]*2.355, 'sig':p_fit[1],\n",
    "                'amp':p_fit[6], 'bkg':p_fit[5], 'fwhm_err':fwhm_err, 'mu_err':mu_err\n",
    "                }\n",
    "            \n",
    "        # compute goodness of fit\n",
    "        rchisq = pgf.goodness_of_fit(hist_norm, b, fit_func, p_fit)\n",
    "        fit_results[ie]['rchisq'] = rchisq\n",
    "        \n",
    "        # Now we can invert the given set of input calibration constants, \n",
    "        # and predict the location of the RAW peak.\n",
    "        # This allows us to refine our estimate of the resolution \n",
    "        # from the initial guess to the final value, just by calling fit_peaks \n",
    "        # multiple times.  \n",
    "        # Hmm, but what if the polynomial has multiple roots!  How do I know which\n",
    "        # root is the correct guess for mu_raw?  How to make this automatic?\n",
    "        # Trick: pick the root that most closely matches what you would get\n",
    "        # by only consdering our 1st-order calibration term from peakdet.\n",
    "        # For a fairly linear system like a Ge detector this should work well.\n",
    "        \n",
    "        pk_guess = fit_results[ie]['mu'] / cal_pars[1]\n",
    "        pk_roots = (pfunc - epk).roots\n",
    "        ipk_closest = (np.abs(pk_roots - pk_guess)).argmin()\n",
    "        mu_raw = pk_roots[ipk_closest]\n",
    "        mu_unc = p_err[1] * (mu_raw / epk)\n",
    "        fit_results[ie]['mu_raw'], fit_results[ie]['mu_unc'] = mu_raw, mu_unc\n",
    "        \n",
    "        # print(epk, (pfunc - epk).roots, p_fit[1] / cal_pars[1] )\n",
    "        # print(ipk_closest)\n",
    "        # print(mu_raw, mu_unc)\n",
    "        \n",
    "        if show_plot:\n",
    "            xfit = np.arange(xlo, xhi, xpb * 0.1)\n",
    "            plt.axvline(bins[ibkg_lo], c='m', label='bkg region')\n",
    "            plt.plot(xfit, fit_func(xfit, *p_init), '-', c='orange', label='init')\n",
    "            plt.plot(xfit, fit_func(xfit, *p_fit), '-', c='red', label='fit')\n",
    "            plt.plot(bins[1:], hist_norm, c='b', lw=1.5, ds='steps')\n",
    "            plt.plot(np.nan, np.nan, 'w', label=f'FWHM: {fwhm:.2f}')\n",
    "            plt.xlabel('pass-1 energy (kev)', ha='right', x=1)\n",
    "            plt.legend(fontsize=12)\n",
    "            if batch:\n",
    "                plt.savefig(f'./plots/energy_cal/fit{ie}_peakfit.png')\n",
    "            else:\n",
    "                plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "    return fit_results\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legend-software",
   "language": "python",
   "name": "legend-software"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
